from nltk.tokenize import word_tokenize
# Initialize training data iterator


phrase = "Hoje ir√° chover, tome cuidado"
